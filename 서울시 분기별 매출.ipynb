{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0439a8c-4384-492d-947f-da2de8b433f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06d1a5d6-b47f-4ca9-9efa-2939aa202847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[START] seoul_sales_2023.csv\n",
      "[FAIL] seoul_sales_2023.csv -> \"['시간대_00_06_매출_건수', '시간대_06_11_매출_건수', '시간대_11_14_매출_건수', '시간대_14_17_매출_건수', '시간대_17_21_매출_건수', '시간대_21_24_매출_건수'] not in index\"\n",
      "\n",
      "[START] seoul_sales_2024.csv\n",
      "[FAIL] seoul_sales_2024.csv -> \"['시간대_00_06_매출_건수', '시간대_06_11_매출_건수', '시간대_11_14_매출_건수', '시간대_14_17_매출_건수', '시간대_17_21_매출_건수', '시간대_21_24_매출_건수'] not in index\"\n",
      "\n",
      "[START] seoul_sales_20251.csv\n",
      "[FAIL] seoul_sales_20251.csv -> 필수 컬럼 누락: {'행정동_코드', '기준_년분기_코드', '서비스_업종_코드'}\n",
      "\n",
      "[START] seoul_sales_20252.csv\n",
      "[FAIL] seoul_sales_20252.csv -> 필수 컬럼 누락: {'행정동_코드', '기준_년분기_코드', '서비스_업종_코드'}\n",
      "\n",
      "===================================\n",
      "files ok=0, fail=4\n",
      "ALL DONE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "\n",
    "# ===== 설정 =====\n",
    "ROOT_DIR = r\"C:\\Users\\user\\Documents\\서울시_포폴\\서울시분기별매출\"\n",
    "TABLE = \"stg_seoul_sales_quarter\"\n",
    "\n",
    "MYSQL = dict(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"********\",\n",
    "    db=\"seoul\",\n",
    "    port=3306,\n",
    "    charset=\"utf8mb4\",\n",
    "    autocommit=False\n",
    ")\n",
    "\n",
    "CHUNK_SIZE = 20000\n",
    "\n",
    "# ===== 유틸 =====\n",
    "def read_csv_auto(path):\n",
    "    for enc in (\"utf-8-sig\", \"cp949\", \"euc-kr\"):\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except Exception:\n",
    "            pass\n",
    "    raise ValueError(f\"인코딩 실패: {path}\")\n",
    "\n",
    "def normalize_cols(df):\n",
    "    # 컬럼명 좌우 공백 제거\n",
    "    df.columns = df.columns.astype(str).str.strip()\n",
    "\n",
    "    # ~ 를 _ 로 통일 (시간대_00~06 → 시간대_00_06)\n",
    "    rename = {}\n",
    "    for c in df.columns:\n",
    "        c2 = c.replace(\"~\", \"_\")\n",
    "        # 건수 컬럼이 '시간대_건수~06_매출_건수'처럼 이상하게 들어온 경우가 있어 보여서 정리\n",
    "        c2 = c2.replace(\"시간대_건수_\", \"시간대_\")\n",
    "        rename[c] = c2\n",
    "    return df.rename(columns=rename)\n",
    "\n",
    "def to_int_cols(df, exclude):\n",
    "    df = df.copy()\n",
    "    for c in df.columns:\n",
    "        if c in exclude:\n",
    "            continue\n",
    "        # 숫자 문자열에 콤마가 있을 가능성 대비\n",
    "        df[c] = (df[c].astype(str)\n",
    "                 .str.replace(\",\", \"\", regex=False)\n",
    "                 .str.strip())\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def get_insert_sql(cols):\n",
    "    col_sql = \",\".join([f\"`{c}`\" for c in cols])\n",
    "    placeholders = \",\".join([\"%s\"] * len(cols))\n",
    "    return f\"INSERT IGNORE INTO {TABLE} ({col_sql}) VALUES ({placeholders})\"\n",
    "\n",
    "def load_sales_files():\n",
    "    conn = pymysql.connect(**MYSQL)\n",
    "\n",
    "    files = sorted(Path(ROOT_DIR).glob(\"seoul_sales_*.csv\"))\n",
    "    if not files:\n",
    "        raise ValueError(\"seoul_sales_*.csv 파일을 못 찾았어. 경로 확인해줘.\")\n",
    "\n",
    "    # DB 컬럼 순서 (DDL 기준)\n",
    "    cols = [\n",
    "        \"기준_년분기_코드\",\"행정동_코드\",\"행정동_코드_명\",\"서비스_업종_코드\",\"서비스_업종_코드_명\",\n",
    "        \"당월_매출_금액\",\"당월_매출_건수\",\n",
    "        \"주중_매출_금액\",\"주말_매출_금액\",\"월요일_매출_금액\",\"화요일_매출_금액\",\"수요일_매출_금액\",\n",
    "        \"목요일_매출_금액\",\"금요일_매출_금액\",\"토요일_매출_금액\",\"일요일_매출_금액\",\n",
    "        \"시간대_00_06_매출_금액\",\"시간대_06_11_매출_금액\",\"시간대_11_14_매출_금액\",\n",
    "        \"시간대_14_17_매출_금액\",\"시간대_17_21_매출_금액\",\"시간대_21_24_매출_금액\",\n",
    "        \"남성_매출_금액\",\"여성_매출_금액\",\n",
    "        \"연령대_10_매출_금액\",\"연령대_20_매출_금액\",\"연령대_30_매출_금액\",\"연령대_40_매출_금액\",\n",
    "        \"연령대_50_매출_금액\",\"연령대_60_이상_매출_금액\",\n",
    "        \"주중_매출_건수\",\"주말_매출_건수\",\"월요일_매출_건수\",\"화요일_매출_건수\",\"수요일_매출_건수\",\n",
    "        \"목요일_매출_건수\",\"금요일_매출_건수\",\"토요일_매출_건수\",\"일요일_매출_건수\",\n",
    "        \"시간대_00_06_매출_건수\",\"시간대_06_11_매출_건수\",\"시간대_11_14_매출_건수\",\n",
    "        \"시간대_14_17_매출_건수\",\"시간대_17_21_매출_건수\",\"시간대_21_24_매출_건수\",\n",
    "        \"남성_매출_건수\",\"여성_매출_건수\",\n",
    "        \"연령대_10_매출_건수\",\"연령대_20_매출_건수\",\"연령대_30_매출_건수\",\"연령대_40_매출_건수\",\n",
    "        \"연령대_50_매출_건수\",\"연령대_60_이상_매출_건수\",\n",
    "        \"source_file\"\n",
    "    ]\n",
    "\n",
    "    sql = get_insert_sql(cols)\n",
    "\n",
    "    ok, fail = 0, 0\n",
    "    with conn.cursor() as cur:\n",
    "        for f in files:\n",
    "            path = str(f)\n",
    "            print(f\"\\n[START] {f.name}\")\n",
    "\n",
    "            try:\n",
    "                df = read_csv_auto(path)\n",
    "                df = normalize_cols(df)\n",
    "\n",
    "                # 필수 컬럼 체크\n",
    "                required = {\"기준_년분기_코드\",\"행정동_코드\",\"서비스_업종_코드\"}\n",
    "                missing = required - set(df.columns)\n",
    "                if missing:\n",
    "                    raise ValueError(f\"필수 컬럼 누락: {missing}\")\n",
    "\n",
    "                # 문자열 컬럼 제외하고 숫자 변환\n",
    "                exclude = {\"기준_년분기_코드\",\"행정동_코드_명\",\"서비스_업종_코드\",\"서비스_업종_코드_명\"}\n",
    "                df = to_int_cols(df, exclude=exclude)\n",
    "\n",
    "                # 행정동_코드가 숫자인지(문자면 숫자화)\n",
    "                df[\"행정동_코드\"] = pd.to_numeric(df[\"행정동_코드\"], errors=\"coerce\")\n",
    "                df = df.dropna(subset=[\"기준_년분기_코드\",\"행정동_코드\",\"서비스_업종_코드\"])\n",
    "\n",
    "                df[\"행정동_코드\"] = df[\"행정동_코드\"].astype(int)\n",
    "\n",
    "                df[\"source_file\"] = f.name\n",
    "\n",
    "                # NaN -> None\n",
    "                sub = df[cols].astype(object).where(pd.notnull(df[cols]), None)\n",
    "                data = [tuple(r) for r in sub.to_numpy()]\n",
    "\n",
    "                for i in range(0, len(data), CHUNK_SIZE):\n",
    "                    cur.executemany(sql, data[i:i+CHUNK_SIZE])\n",
    "                    print(f\"  inserted {min(i+CHUNK_SIZE, len(data))}/{len(data)}\")\n",
    "\n",
    "                conn.commit()\n",
    "                ok += 1\n",
    "                print(f\"[DONE] {f.name} rows={len(df)}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                conn.rollback()\n",
    "                fail += 1\n",
    "                print(f\"[FAIL] {f.name} -> {e}\")\n",
    "\n",
    "    conn.close()\n",
    "    print(\"\\n===================================\")\n",
    "    print(f\"files ok={ok}, fail={fail}\")\n",
    "    print(\"ALL DONE\")\n",
    "\n",
    "# 실행\n",
    "load_sales_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce45d881-e9cd-4a4e-a4d1-3c6cdc18ce9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e5b01-e232-499b-85b3-62bf27f675cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866faa8d-f42f-466d-ab33-4951c879258c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d29b6e-ebde-4dc8-b161-416fc55c92df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03063898-54dd-44cb-af6c-cdaa80c9553b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f8d81-1a5f-4a2c-9dad-cae816862d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58960aa-92f8-4792-a5f4-add42861e0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a4a94b-0fa3-4d6d-95fb-9f1b7f1fadd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859cd98e-7017-42a3-903d-6d895bbde13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115b9dfb-fccc-46a7-a0dd-b0ab59f3217d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec123651-3346-4ac0-9435-092d98156c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
